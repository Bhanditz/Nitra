using Nemerle;
using Nemerle.Collections;
using Nemerle.Imperative;
using Nemerle.Text;
using Nemerle.Utility;

using Nitra.Runtime.Reflection;
using System;
using System.Collections.Generic;
using System.Linq;

namespace Nitra.Internal.Recovery
{
  [Record]
  public class AstPatcher
  {
    [Record]
    public class SimpleAst
    {
      public ParsedSequence : ParsedSequence;
      public End            : int;
      public Fields         : array[int];

      [RecordIgnore]
      public mutable Ptr    : int = -1;

      public Size           : int { get { Fields.Sum() } }
    }

    [Record]
    public class ExtensionAst
    {
      public ParsedSequence : ParsedSequence;
      public End            : int;

      [RecordIgnore]
      public mutable Ptr    : int = -1;

      [RecordIgnore]
      public mutable BP     : int = int.MaxValue;

      [RecordIgnore]
      public Extensions     : Dictionary[int, SimpleAst] = Dictionary();

      public Size           : int { get { End - ParsedSequence.StartPos } }
    }

    private _recoveryParser : RecoveryParser;
    private _memiozation : Dictionary[ParsedSequenceKey, SequenceTokenChanges];

    [RecordIgnore]
    public _simple : Hashtable[int * ParsingSequence, SimpleAst] = Hashtable();

    [RecordIgnore]
    public _extension : Hashtable[int * bool * ExtensibleRuleParserData, ExtensionAst] = Hashtable();

    [RecordIgnore]
    public _toProcess : System.Collections.Generic.Stack[ParsedSequence * int] = System.Collections.Generic.Stack();

    private static Fail : int = int.MaxValue;

    private FirstSubrule(seq : ParsedSequence, subrules : array[ParsedSubrule]) : ParsedSubrule
    {
      foreach (newSubrule in seq.GetFirstSubrules(subrules).OrderBy(s => s.Begin).ThenBy(s => s.State))
        return newSubrule;
      ParsedSubrule(-1, -1, -1)
    }

    private NextSubrule(seq : ParsedSequence, subrules : array[ParsedSubrule], curSubrule : ParsedSubrule) : ParsedSubrule
    {
      foreach (newSubrule in seq.GetNextSubrules(curSubrule, subrules))
        return newSubrule;
      ParsedSubrule(-1, -1, -1)
    }

    public ParseSequence(seq : ParsedSequence, end : int) : void
    {
      def makeSequence(seq : ParsedSequence, end : int) : SimpleAst
      {
        def (parses, tokenChanges) = _memiozation[ParsedSequenceKey(seq, end)];
        when (tokenChanges.IsFail)
          assert3(false);

        def subrules = parses.Keys.ToArray();

        def ast = SimpleAst(seq, end, array(seq.ParsingSequence.SequenceInfo.Subrules.Length));
        for (mutable subrule = FirstSubrule(seq, subrules); subrule.State >= 0; subrule = NextSubrule(seq, subrules, subrule))
        {
          def state = seq.ParsingSequence.States[subrule.State];
          def index = state.Subrule.Offset - 3;//TODO: FIXME HACK!
          def size = subrule.End - subrule.Begin;
          ast.Fields[index] += size;

          def sequences = seq.GetSequencesForSubrule(subrule).ToArray();
          if (sequences.Length > 0)
          {
            assert3(sequences.Length == 1);
            assert(_memiozation[ParsedSequenceKey(sequences[0], subrule.End)].TotalTokenChanges == parses[subrule]);
            _toProcess.Push(sequences[0], subrule.End);
          }
          else
          {
            when (state is ParsingState.Subsequence as state when state.SequenceInfo.Description == "IgnoreToken")//TODO: Hardcode
            when (_recoveryParser.ParseResult.TryGetAst(subrule.Begin, state.SequenceInfo.Id) <= 0)
            {
              def ptr = _recoveryParser.ParseResult.Allocate(state.SequenceInfo.AstSize, state.SequenceInfo.Id);
              _recoveryParser.ParseResult.ast[ptr + ExtensibleRuleParser.AstOfs.Next] = _recoveryParser.ParseResult.memoize[subrule.Begin];
              _recoveryParser.ParseResult.memoize[subrule.Begin] = ptr;

              def error = ParseErrorData(NSpan(subrule.Begin, subrule.End));
              def index = _recoveryParser.ParseResult.ErrorData.Count;
              _recoveryParser.ParseResult.ErrorData.Add(error);
              _recoveryParser.ParseResult.ast[ptr + state.SequenceInfo.Subrules[0].Offset] = ~index;
              _recoveryParser.ParseResult.ast[ptr + ExtensibleRuleParser.AstOfs.State] = Nitra.ParseResult.AstParsedState;
            }
          }
        }
        assert3(ast.Size == end - seq.StartPos);
        ast
      }

      match (seq.ParsingSequence)
      {
        | Sequence =>
          mutable ast;
          when (_simple.TryGetValue((seq.StartPos, seq.ParsingSequence), out ast))
          {
            assert3(ast.Size == end - seq.StartPos);
            return;
          }

          ast = makeSequence(seq, end);
          _simple.Add((seq.StartPos, seq.ParsingSequence), ast);

        | Extensible as parsingSequence =>
          def (parses, tokenChanges)= _memiozation[ParsedSequenceKey(seq, end)];
          when (tokenChanges.IsFail)
            assert3(false);

          def subrules = parses.Keys.ToArray();

          mutable isPrefix = true;
          for (mutable subrule = FirstSubrule(seq, subrules); subrule.State >= 0; { subrule = NextSubrule(seq, subrules, subrule); isPrefix = false })
          {
            when (!isPrefix && subrule.Begin == subrule.End)
              continue;
            def key = (subrule.Begin, isPrefix, parsingSequence.RuleParser.ParserData);
            mutable ast;
            when (_extension.TryGetValue(key, out ast))
            {
              assert3(ast.Size == end - seq.StartPos);
              ast.BP = Math.Min(ast.BP, parsingSequence.RuleParser.BindingPower);
              continue;
            }
            ast = ExtensionAst(seq, end);
            ast.BP = parsingSequence.RuleParser.BindingPower;
            _extension.Add(key, ast);

            foreach (sequence in seq.GetSequencesForSubrule(subrule))
              when (_memiozation[ParsedSequenceKey(sequence, subrule.End)].TotalTokenChanges == parses[subrule])
              {
                def ext = makeSequence(sequence, subrule.End);
                ast.Extensions.Add(sequence.ParsingSequence.SequenceInfo.Id, ext);
                _toProcess.Push(sequence, subrule.End);
              }
          }
          //assert3(ast.Size == end - seq.StartPos);
      }
    }

    public static Patch(startSeq : ParsedSequence, recoveryParser : RecoveryParser, memiozation : Dictionary[ParsedSequenceKey, SequenceTokenChanges]) : void
    {
      def astBuilder = AstPatcher(recoveryParser, memiozation);
      astBuilder.ParseSequence(startSeq, recoveryParser.ParseResult.Text.Length);
      while (astBuilder._toProcess.Count > 0)
        astBuilder.ParseSequence(astBuilder._toProcess.Pop());
      def parseResult = recoveryParser.ParseResult;
      def fillAst(ast)
      {
        def info = ast.ParsedSequence.ParsingSequence.SequenceInfo;
        def subrules = info.Subrules;
        for (mutable i = 0; i < subrules.Length; ++i)
          parseResult.ast[ast.Ptr + subrules[i].Offset] = ast.Fields[i];

        parseResult.ast[ast.Ptr + ExtensibleRuleParser.AstOfs.State] = Nitra.ParseResult.AstParsedState;
      }

      foreach (ast in astBuilder._simple.Values)
      {
        def startPos = ast.ParsedSequence.StartPos;
        def info = ast.ParsedSequence.ParsingSequence.SequenceInfo;
        ast.Ptr = parseResult.TryGetAst(startPos, info.Id);
        when (ast.Ptr <= 0)
        {
          ast.Ptr = parseResult.Allocate(info.AstSize, info.Id);
          parseResult.ast[ast.Ptr + ExtensibleRuleParser.AstOfs.Next] = parseResult.memoize[startPos];
          parseResult.memoize[startPos] = ast.Ptr;
        }
        fillAst(ast);
      }

      foreach (((startPos, isPrefix, parserData), ast) in astBuilder._extension.KeyValuePairs)
      {
        ast.Ptr = parseResult.TryGetAst(startPos, if (isPrefix) parserData.PrefixId else parserData.PostfixId);
        def fillPointers(mutable ptr)
        {
          for (; ptr > 0; ptr = parseResult.ast[ptr + ExtensibleRuleParser.AstOfs.Next])
          {
            def id = parseResult.ast[ptr + ExtensibleRuleParser.AstOfs.Id] & ExtensibleRuleParser.AstMask.Id;
            mutable ext;
            when (ast.Extensions.TryGetValue(id, out ext))
              ext.Ptr = ptr;
          }
        }
        def buildList(parsers)
        {
          mutable prevExtPtr = 0;
          for (mutable i = parsers.Length - 1; i >= 0; --i)
          {
            def extParser = parsers[i];
            def info = extParser.Reflection(extParser.RuleId);
            when (ast.Extensions.ContainsKey(extParser.RuleId))
            {
              def isBest = prevExtPtr == 0;
              def ext = ast.Extensions[extParser.RuleId];
              when (ext.Ptr <= 0)
                ext.Ptr = parseResult.Allocate(info.AstSize, info.Id);
              parseResult.ast[ext.Ptr + ExtensibleRuleParser.AstOfs.Next] = prevExtPtr;
              prevExtPtr = ext.Ptr;
              parseResult.ast[ext.Ptr + ExtensibleRuleParser.AstOfs.Id] = info.Id | if (isBest) ExtensibleRuleParser.AstFlags.Best else ExtensibleRuleParser.AstFlags.Equal;
              fillAst(ext);
            }
          }
          prevExtPtr
        }
        if (isPrefix)
        {
          when (ast.Ptr <= 0)
          {
            ast.Ptr = parseResult.Allocate(ExtensibleRuleParser.PrefixOfs.NodeSize, parserData.PrefixId);
            parseResult.ast[ast.Ptr + ExtensibleRuleParser.PrefixOfs.Next] = parseResult.memoize[startPos];
            parseResult.memoize[startPos] = ast.Ptr;
          }
          fillPointers(parseResult.ast[ast.Ptr + ExtensibleRuleParser.PrefixOfs.List]);
          parseResult.ast[ast.Ptr + ExtensibleRuleParser.PrefixOfs.List] = buildList(parserData.PrefixParsers);
        }
        else
        {
          when (ast.Ptr <= 0)
          {
            ast.Ptr = parseResult.Allocate(ExtensibleRuleParser.PostfixOfs.NodeSize, parserData.PostfixId);
            parseResult.ast[ast.Ptr + ExtensibleRuleParser.PostfixOfs.Next] = parseResult.memoize[startPos];
            parseResult.memoize[startPos] = ast.Ptr;
          }
          mutable index = 0;
          for (; index < parserData.PostfixParsers.Length; ++index)
            when (ast.BP >= parserData.PostfixDescriptors[index].BindingPower)
              break;
          parseResult.ast[ast.Ptr + ExtensibleRuleParser.PostfixOfs.FirstRuleIndex] = index;
          fillPointers(parseResult.ast[ast.Ptr + ExtensibleRuleParser.PostfixOfs.List]);
          parseResult.ast[ast.Ptr + ExtensibleRuleParser.PostfixOfs.List] = buildList(parserData.PostfixParsers);
        }
      }
    }

    public static FindBestPath(startSeq : ParsedSequence, recoveryParser : RecoveryParser, deletedTokens : Dictionary[ParsedSequenceAndSubrule, bool]) : void
    {
      def astPatcher = AstPatcher2(startSeq, recoveryParser, deletedTokens);
      def time = Diagnostics.Stopwatch.StartNew();
      astPatcher.FindBestPath();
      def time = time.Elapsed;
      def asd = time;
      astPatcher.PatchAst();
    }
  }

  [Record]
  public class AstPatcher2
  {
    private _startSeq        : ParsedSequence;
    private _recoveryParser  : RecoveryParser;
    private _deletedTokens   : Dictionary[ParsedSequenceAndSubrule, bool];
    private _allSubrules     : array[List[ParsedSequence * ParsedSubrule]];
    private _stateEndChanges : Hashtable[ParsedSequence * int * int, TokenChanges] = Hashtable();
    private _subruleChanges  : Hashtable[ParsedSequence * ParsedSubrule, TokenChanges * TokenChanges] = Hashtable();

    public this(startSeq : ParsedSequence, recoveryParser : RecoveryParser, deletedTokens : Dictionary[ParsedSequenceAndSubrule, bool])
    {
      _startSeq       = startSeq;
      _recoveryParser = recoveryParser;
      _deletedTokens  = deletedTokens;
      _allSubrules    = array(_recoveryParser.ParseResult.Text.Length + 1);
    }

    public PatchAst() : void
    {
      foreach (endState in _startSeq.ParsingSequence.EndStates)
      {
        def start = _stateEndChanges.Get(_startSeq, endState, _recoveryParser.ParseResult.Text.Length);
        def asd = start;
      }
    }

    public FindBestPath() : void
    {
      foreach (seq in _recoveryParser.Sequences.Values)
        foreach (subrule in seq.ParsedSubrules)
        {
          when (_allSubrules[subrule.End] == null)
            _allSubrules[subrule.End] = List();
          _allSubrules[subrule.End].Add((seq, subrule));
        }

      foreach (subrules when subrules != null in _allSubrules)
      {
        //Сортировка не влияет на результат. Но уменьшает необходимое колличество итераций.
        subrules.Sort(((_, subrule1), (_, subrule2)) =>
        {
          def c = -subrule1.Begin.CompareTo(subrule2.Begin);
          if (c == 0)
            subrule1.State.CompareTo(subrule2.State);
          else
            c
        });
        for (mutable updated = true; updated;)
        {
          updated = false;
          foreach ((seq, subrule) in subrules)
          {
            def state = seq.ParsingSequence.States[subrule.State];
            def prevChanges = if (seq.StartPos == subrule.Begin && state.IsStart)
              //последовательность всегда начинается без исменений
              //предыдущие изменения суммируются в момент вызова последовательности
              //ибо последовательность может быть вызвана из разных мест
              //и соответственно иметь разное число предыдущих изменений
              TokenChanges(0, 0)
            else
            {
              mutable minChanges = TokenChanges.Fail;
              foreach (prevState in state.Prev)
              {
                mutable curChanges;
                def key = (seq, prevState, subrule.Begin);
                when (_stateEndChanges.TryGetValue(key, out curChanges))
                  minChanges = TokenChanges.Min(curChanges, minChanges);
              }
              minChanges
            }
            def subruleChanges =
            {
              def minChangesFromSequence(parsingSequence, mutable minChanges)
              {
                mutable calledSeq;
                if (_recoveryParser.Sequences.TryGetValue((subrule.Begin, parsingSequence), out calledSeq))
                {
                  foreach (endState in parsingSequence.EndStates)
                  {
                    mutable curChanges;
                    def key = (calledSeq, endState, subrule.End);
                    when (_stateEndChanges.TryGetValue(key, out curChanges))
                      minChanges = TokenChanges.Min(curChanges, minChanges);
                  }
                  minChanges
                }
                else
                  TokenChanges(0, 0);//Нет последовательности. Значит было успешно разобран основным парсером.
              }
              if (_deletedTokens.ContainsKey(ParsedSequenceAndSubrule(seq, subrule)))
                TokenChanges(0, 1);
              else match (state)
              {
                | Predicate => TokenChanges(0, 0)
                | Scan =>
                  if (subrule.IsEmpty)
                    TokenChanges(state.Subrule.MandatoryTokenCount, 0);
                  else
                    TokenChanges(0, 0)

                | Simple           as seq1 with parsingSequence = seq1.RuleParser.ParsingSequence
                | Extensible       as seq2 with parsingSequence = seq2.RuleParser.ParsingSequence
                | Subsequence      as seq5 with parsingSequence = seq5.Sequence =>
                  if (subrule.IsEmpty)
                    TokenChanges(parsingSequence.MandatoryTokenCount, 0);
                  else
                    minChangesFromSequence(parsingSequence, TokenChanges.Fail);

                | ExtensionPrefix  as prefix =>
                  if (subrule.IsEmpty)
                    TokenChanges(prefix.RuleParser.MandatoryTokenCount, 0);
                  else
                  {
                    mutable minChanges = TokenChanges.Fail;
                    foreach (ruleParser in prefix.RuleParser.PrefixRules)
                      minChanges = minChangesFromSequence(ruleParser.ParsingSequence, minChanges);
                    minChanges
                  }

                | ExtensionPostfix as postfix =>
                  if (subrule.IsEmpty)
                    TokenChanges(0, 0);
                  else
                  {
                    mutable minChanges = TokenChanges.Fail;
                    foreach (ruleParser when postfix.RuleParser.FirstPostfixRuleId <= ruleParser.RuleId in postfix.RuleParser.PostfixRules)
                      minChanges = minChangesFromSequence(ruleParser.ParsingSequence, minChanges);
                    minChanges
                  }
              }
            };
            def key = (seq, subrule.State, subrule.End);
            _ = _stateEndChanges.Update(key, TokenChanges.Fail, oldChanges =>
            {
              def newChanges = TokenChanges.Min(oldChanges, prevChanges + subruleChanges);
              when (newChanges != oldChanges)
                updated = true;
              newChanges
            });
            _subruleChanges[(seq, subrule)] = (prevChanges, subruleChanges);
          }
        }
      }
    }
  }
}
