using Nitra.Runtime;

using Nemerle;
using Nemerle.Collections;
using Nemerle.Imperative;
using Nemerle.Text;
using Nemerle.Utility;

using System;
using System.Diagnostics;
using System.Collections.Generic;
using System.Linq;

using SCG = System.Collections.Generic;

namespace Nitra.Internal.Recovery
{
  public partial class RecoveryParser
  {
    public PanicRecovery() : void
    {
      def textPos = 0;
      Records[textPos] = Hashtable();
      def rootParsingSequence =
        match (ParseResult.RuleParser)
        {
          | SimpleRuleParser     as ruleParser => ruleParser.ParsingSequence
          | ExtensibleRuleParser as ruleParser => ruleParser.ParsingSequence
          | _                                  => assert3(false)
        };
      def completeRecord = ParseRecord(StartParseSequence(textPos, rootParsingSequence, TokenChanges.None), -1, ParseResult.Text.Length);
      Parse();

      def memoization = SCG.Dictionary();
      def grammar = this.ParseResult.RuleParser.Grammar;
      def parseResult = this.ParseResult;
      
      def isRootRecordCompleted() { def records = Records[ParseResult.Text.Length]; records != null && records.Contains(completeRecord) }
      mutable prevMaxPos = -1;
      while (!isRootRecordCompleted())
      {
        ParseToFailPos();
        mutable curMaxPos = MaxPos;
        when (curMaxPos == prevMaxPos)
        {
          curMaxPos = DeleteNextToken(grammar, curMaxPos, parseResult);
          Parse();
          continue;
        }
        prevMaxPos = MaxPos;
        
        def records = Records[curMaxPos].MapToArrayFiltered(r => !r.Key.IsComplete && !IsInsideToken(memoization, grammar, r.Key.Sequence), r => r.Key);
        def leafRecords = GetLeafTokens(records);
        
        Debug.IndentSize = 2;
        Debug.WriteLine("----------------------------------------");
        foreach (record in records)
          PrintRecordParents(record);
        Debug.WriteLine("++++++++++++++++++++++++++++++++++++++++");
        foreach (record in leafRecords)
          PrintRecordParents(record);
        Debug.WriteLine("========================================");
        
        def text = parseResult.Text;
        when (curMaxPos == text.Length)
        {
          while (!isRootRecordCompleted())
          {
            InsertSubrules(text.Length);
            Parse();
          }
          break;
        }
        
        def addStopperToken(record : ParseRecord, next : int, result : Hashtable[_, _], tokenParser : TokenParser)
        {
          mutable value;
          unless (result.TryGetValue(tokenParser, out value))
          {
            value = HashSet();
            result.Add(tokenParser, value);
          }
                  
          _ = value.Add((record, next));
        }
        def calcFollowSet(record : ParseRecord, result : Hashtable[TokenParser, _]) : void
        {
          Debug.WriteLine(record);
          
          def processNextState(parsingState : ParsingState)
          {
            def record = record;
            def result = result;
            foreach (next in parsingState.Next)
            {
              when (next >= 0)
              {
                def nextState = record.Sequence.ParsingSequence.States[next];
                def tokenParser = grammar.GetTokenParser(nextState.Subrule);
                if (tokenParser != null)
                {
                  if (tokenParser.IsVoid)
                    processNextState(nextState);
                  else
                    addStopperToken(record, next, result, tokenParser);
                }
                else
                  foreach (tokenParser in nextState.FirstTokens)
                    addStopperToken(record, next, result, tokenParser);
              }
            }
            
            foreach (caller in record.Sequence.Callers)
              calcFollowSet(caller, result);
          }
          
          processNextState(record.ParsingState);
        }
        
        def stopperTokens = Hashtable();
        foreach (leafRecord in leafRecords)
          if (leafRecord.ParsingState.IsStart)
          {
            foreach (tokenParser in leafRecord.ParsingState.FirstTokens)
              addStopperToken(leafRecord, -1, stopperTokens, tokenParser);
            foreach (caller in leafRecord.Sequence.Callers)
              calcFollowSet(caller, stopperTokens);
          }
          else
            calcFollowSet(leafRecord, stopperTokens);
          
        
        deletToken :
        {
          while (curMaxPos < text.Length)
          {
            foreach (stopperToken in stopperTokens)
            {
              def pos = stopperToken.Key.Parse(curMaxPos, text, parseResult);
              when (pos <= curMaxPos)
                continue;
              
              Parse();
              foreach ((oldRecord, newState) in stopperToken.Value.Distinct())
              {
                when (newState < 0)
                  break;
                  
                def curRecords = Records[curMaxPos];
                def newRecord = ParseRecord(oldRecord.Sequence, oldRecord.State, curMaxPos);

                def record = if (curRecords.ContainsKey(newRecord))
                  newRecord
                else if (oldRecord.ParsePos == oldRecord.Sequence.StartPos && oldRecord.ParsingState.IsStart)
                  ParseRecord(Sequences[curMaxPos, oldRecord.Sequence.ParsingSequence], oldRecord.State, curMaxPos);
                else
                {
                  assert2(false);
                  assert(false);
                }

                def tokenChanges = curRecords[record];
                def subruleTokenChanges = TokenChanges(inserted = oldRecord.ParsingState.MandatoryTokenCount, deleted = 0);
                SubruleParsed(curMaxPos, curMaxPos, record, tokenChanges, subruleTokenChanges);
              }
              //InsertSubrules(curMaxPos);
              // востановление состояния парсера, так чтобы он парсил с сабруля для которого 
              deletToken();
            }
            
            curMaxPos = DeleteNextToken(grammar, curMaxPos, parseResult);
          }
        }
        
        Parse();
      }

      BuildAst();
    }
    
    PrintRecordParents(record : ParseRecord) : void
    {
      Debug.WriteLine(record);
      Debug.Indent();
      foreach (caller in record.Sequence.Callers)
        PrintRecordParents(caller);
      Debug.Unindent();
    }
    
    DeleteNextToken(grammar : CompositeGrammar, pos : int, parseResult : ParseResult) : int
    {
      mutable max;
      def tokens = grammar.ParseGrammarTokens(pos, parseResult);
      max = if (tokens.Count > 0) tokens.Max(t => t[0]) else pos;
      when (max > pos)
      {
        this.Delete(pos, max);
        return max;
      }
      
      def text = parseResult.Text;

      // Удаеляем грязь по одному символу.
      for (mutable i = pos; i < text.Length; i++)
      {
        def tokens = grammar.ParseGrammarTokens(i, parseResult);
        when (tokens.Count > 0)
        {
          this.Delete(pos, i);
          return i;
        }
      }
      
      this.Delete(pos, text.Length);
      text.Length
    }
    
    
    GetLeafTokens(records : Seq[ParseRecord]) : SCG.List[ParseRecord]
    {
      def parents = SCG.HashSet();
      
      foreach (record in records)
        foreach (caller in record.Sequence.Callers)
          _ = parents.Add(caller);
          
      def result = SCG.List();
      
      foreach (record in records)
        unless (parents.Contains(record))
          unless (record.ParsingState.IsVoid)
            result.Add(record);
        
      result
    }
  }
}
