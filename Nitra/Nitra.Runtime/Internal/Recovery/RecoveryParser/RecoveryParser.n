using Nemerle;
using Nemerle.Collections;
using Nemerle.Imperative;
using Nemerle.Text;
using Nemerle.Utility;
using Nemerle.Extensions;

using Nitra.Collections;
using Nitra.Runtime;
using Nitra.Runtime.Reflection;

using System;
using System.Diagnostics;
using System.IO;
using System.Linq;

using SCG = System.Collections.Generic;

namespace Nitra.Internal.Recovery
{
  public partial class RecoveryParser
  {
    public ParseResult       : ParseResult;
    public Sequences         : Hashtable[int * ParsingSequence, ParsedSequence] = Hashtable();
    public Records           : array[Hashtable[ParseRecord, TokenChanges]];
    public RecordsToProcess  : PriorityQueue[ParseRecord * TokenChanges] = PriorityQueue(
      fun ((l, lTokenChanges), (r, rTokenChanges))
      {
        if (l.IsComplete) if (r.IsComplete) return 0 else return -1;
        else              if (r.IsComplete) return 1 else ();
        def c = lTokenChanges.CompareTo(rTokenChanges);
        if (c != 0)
          c
        else
          l.ParsePos.CompareTo(r.ParsePos)
      });

    public mutable MaxPos    : int = 0;
    public mutable BestSolution : TokenChanges = TokenChanges.Fail;

    public StartSequence : ParsedSequence { get { this.Sequences[0, this.ParseResult.RuleParser.ParsingSequence] } }

    public this(parseResult : ParseResult)
    {
      Records     = array(parseResult.Text.Length + 1);
      ParseResult = parseResult;
    }

    private ErrorPositions : SCG.HashSet[int] = SCG.HashSet();

    public CollectKeywordCompletionList(completionStartPos : int, completionPrefix : string, failPos : int) : void
    {
      def len = completionPrefix.Length;
      when (len > 42)
        return;
      def prefix = completionPrefix;
        
      def records = Records[failPos];
      
      when (records == null)
        return;
        
      def result = SCG.HashSet();
      foreach (record when !record.Key.IsComplete in records)
        when (record.Key.ParsingState is ParsingState.Scan(Subrule=SubruleInfo.TokenString(Str=keyword)) when keyword.StartsWith(prefix, StringComparison.InvariantCultureIgnoreCase))
          _ = result.Add(keyword);
          
      throw LiteralCompletionException(result.OrderBy(x => x).ToArray())
    }

    public RecoveryFromAllErrors() : void
    {
      def completionPrefix   = ParseResult.ParserHost.CompletionPrefix;
      def completionStartPos = ParseResult.ParserHost.CompletionStartPos;
      def timer = Stopwatch.StartNew();
      def timeout = timer.Elapsed + ParseResult.ParserHost.RecoveryTimeout;
      def textPos = 0;
      Records[textPos] = Hashtable();
      match (ParseResult.RuleParser)
      {
        | SimpleRuleParser     as ruleParser => _ = StartParseSequence(textPos, ruleParser.ParsingSequence, TokenChanges.None);
        | ExtensibleRuleParser as ruleParser => _ = StartParseSequence(textPos, ruleParser.ParsingSequence, TokenChanges.None);
        | _                                  => assert3(false)
      }
      Parse();

      mutable prevMaxPos = -1;
      while (BestSolution.IsFail)
      {
        ParseToFailPos();
        def curMaxPos = MaxPos;
        prevMaxPos = MaxPos;

        when (completionPrefix != null && MaxPos >= completionStartPos)
          CollectKeywordCompletionList(completionStartPos, completionPrefix, MaxPos);
        
        _ = ErrorPositions.Add(curMaxPos);
        InsertSubrules(curMaxPos);
        //Parse();
        //when (curMaxPos == MaxPos)
          DeleteTokenOrGarbage(curMaxPos, forceDelete = curMaxPos == prevMaxPos);
        //when (RecordsToProcess.Count == 0 && RecordsToComplete.Count == 0)
        //{
        //  BestSolution = BestSolution;
        //  throw Exception("Recovery fail.");
        //}
        Parse();
        when (timer.Elapsed > timeout)
        {
          Delete(curMaxPos, ParseResult.Text.Length);
          Parse();
        }
      }

      BuildRecoveredParseTree();
    }

    private ParseToFailPos() : void
    {
      def memoization = SCG.Dictionary();
      def grammar = this.ParseResult.RuleParser.Grammar;

      mutable maxPos;
      do
      {
        maxPos = MaxPos;
        mutable count;
        do
        {
          def records = Records[maxPos].KeyValuePairs.ToArray(); // to materialize collection
          count = records.Length;

          // Находим все состояния которые могут съедать мусор
          foreach ((record, tokenChanges) in records)
            when (record.State >= 0)
            {
              def state = record.ParsingState;
              foreach (seq in state.CalleeSequences)
                when (seq.CanConsumeErrorTokens)
                {
                  PredictionOrScanning(record, tokenChanges, false);
                  break;
                }
            }

          def sequences = SCG.HashSet(Records[maxPos].Keys.Select(r => r.Sequence));
          foreach (sequence when sequence.ParsingSequence.SequenceInfo != null in sequences)
          {
            when (IsInsideToken(memoization, grammar, sequence) && !sequence.ParsingSequence.CanConsumeErrorTokens)
              continue;
            foreach ((subrule, _) in sequence.ParsedSubrules.KeyValuePairs.NToArray())//TODO optimize
              when (subrule.State >= 0 && subrule.End == maxPos)
              {
                def record = ParseRecord(sequence, subrule.State, subrule.Begin);
                PredictionOrScanning(record, Records[record.ParsePos][record], false);
              }
          }
          Parse();
        }
        while (count < Records[maxPos].Count);
      }
      while (maxPos < MaxPos);
    }

    private static IsInsideToken(memoization : SCG.Dictionary[ParsedSequence, bool], compositeGrammar : CompositeGrammar, seq : ParsedSequence) : bool
    {
      mutable res;
      when (memoization.TryGetValue(seq, out res))
        return res;

      when (seq.ParsingSequence.SequenceInfo is SequenceInfo.Root)
      {
        def parser = seq.ParsingSequence.SequenceInfo.Parser;
        res = compositeGrammar.Tokens.ContainsKey(parser) || compositeGrammar.VoidTokens.ContainsKey(parser);
        memoization[seq] = res;
        when (res)
          return res;
      }

      foreach (caller in seq.Callers)
      {
        res = IsInsideToken(memoization, compositeGrammar, caller.Sequence);
        when (res)
        {
          memoization[seq] = true;
          return true;
        }
      }

      memoization[seq] = false;
      false
    }

    internal static ParsingOrderSubrulesComparison : Comparison[ParsedSubrule * TokenChanges] = ((l, _), (r, _)) =>
    {
      res:
        {
          mutable c;
          c = l.Begin.CompareTo(r.Begin); when (c != 0) res(c);
          c = l.End.CompareTo(r.End); when (c != 0) res(c);
          l.State.CompareTo(r.State);
        }
    };
  }
}
